{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a6b164-6ccd-425e-8d78-59eb00dde803",
   "metadata": {},
   "source": [
    "# Large language model fine tuning\n",
    "In this notebook we will fine-tune an openai chatGPT model to become a bio-image analysis expert which responds with recent Python code for processing images.\n",
    "\n",
    "See also:\n",
    "* [lazyprogrammer tutorial](https://lazyprogrammer.me/how-to-fine-tune-chatgpt-gpt-3-5-turbo-using-the-openai-api-in-python/)\n",
    "* [openai blog](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)\n",
    "* [openai tutorial](https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model)\n",
    "* [openai documentation](https://platform.openai.com/docs/api-reference/fine-tuning/create)\n",
    "* [datacamp tutorial](https://www.datacamp.com/tutorial/fine-tuning-gpt-3-using-the-open-ai-api-and-python)\n",
    "\n",
    "Todo: We could submit training and validation data separately. This notebook does not cover this yet due to limited training data. As soon as we have a larger pool of training data, we can give this a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01ed3ec-c34c-47ef-b1e8-87e8c5b575da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d5a6ed-4bcc-46cf-a179-401ff432fc07",
   "metadata": {},
   "source": [
    "We first set up training data, a list of chat examples. Most code examples used below are taken from the [BioImageAnalysisNotebooks](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3f4a69-f8d1-46e7-8726-722fbfac0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35d162f-322c-444e-af17-a29f99ae6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_example(input, output):\n",
    "    training_data.append(\n",
    "    {\n",
    "      \"messages\": [\n",
    "          { \"role\": \"system\", \"content\": \"\"\"\n",
    "You are a chatbot with strong bio-image analysis expertise.\n",
    "You are an expert python programmer. \n",
    "The code you produce will be executed from a Jupyter notebook.\n",
    "\"\"\"},\n",
    "          {\"role\": \"user\", \"content\": input},\n",
    "          {\"role\": \"assistant\", \"content\": output}\n",
    "      ]       \n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a2f2d0-0554-4d7a-9b26-7d7d5dc98820",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can one open CZI or LIF files using Python?\n",
    "\"\"\", output=\"\"\"\n",
    "To open CZI or LIF files, you can use the AICSImageIO package. \n",
    "In the following code the file `filename` will be loaded and \n",
    "the image data will be stored in `image`.\n",
    "\n",
    "```python\n",
    "from aicsimageio import AICSImage\n",
    "aics_image = AICSImage(\"../../data/EM_C_6_c0.ome.tif\")\n",
    "aics_image\n",
    "```\n",
    "\n",
    "np_image = aics_image.get_image_data(\"ZYX\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5174748b-6973-4ed7-86d0-84c22f0b7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can one show an image, its histogram and some basic statistics in a Jupyter notebook?\n",
    "\"\"\", output=\"\"\"\n",
    "You can show an image stored in the variable `image`, its histogram and some basic statistics using the `stackview` library:\n",
    "\n",
    "```python\n",
    "import stackview\n",
    "\n",
    "stackview.insight(image)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593c0574-8638-45e7-aac1-9515296b8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can one show a label image with every label in a different colour in a Jupyter notebook?\n",
    "\"\"\", output=\"\"\"\n",
    "You can show an image stored in the variable `image`, its histogram and some basic statistics using the `stackview` library:\n",
    "\n",
    "```python\n",
    "import stackview\n",
    "\n",
    "stackview.insight(image)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab81c631-797c-4dec-a954-c3b2445fd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I show an image in Napari?\n",
    "\"\"\", output=\"\"\"\n",
    "Napari is a Python based image viewer and you can use it for showing images and label images like demonstrateed in the following:\n",
    "```python\n",
    "import napari\n",
    "\n",
    "# create a viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# show an image in the viewer\n",
    "viewer.add_image(image)\n",
    "\n",
    "# show a label image in the viewer\n",
    "viewer.add_labels(label_image)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5ea1b9-01f2-46af-8c00-7dddec16885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I remove the background in an image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can remove the background in an image using scikit-image's `white_tophat` function. \n",
    "In the following example the `input_image` will be background-subtracted and \n",
    "the result is stored in `output_image`. \n",
    "The variable `radius` allows to specify how large objects should stay while removing the background.\n",
    "\n",
    "```python\n",
    "from skimage.morphology import disk\n",
    "from skimage.morphology import white_tophat\n",
    "\n",
    "radius = 25\n",
    "\n",
    "output_image = white_tophat(input_image, disk(radius))\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f53cdf-bcfe-431b-8c91-c483fae4bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I remove noise in an image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can denoise an image using the median filter, e.g. using scikit-image:\n",
    "In the following example the noise from `input_image` will be removed and \n",
    "the result is stored in `output_image`\n",
    "\n",
    "```python\n",
    "output_image = filters.median(input_image, disk(1))\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8b0412-c5a1-447d-a498-ff1a95aab06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I segment small roundish objects, such as nuclei or granules, in an image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can segment and label small roundish objects in an image using the Voronoi-Otsu-Labeling algorithm.\n",
    "In the following example the objects in `input_image` will be segmented and \n",
    "the resulting objects will be labeled and stored in the `label_image`.\n",
    "The algorithm has two parameters:\n",
    "* `spot_sigma` allows you to configure how large the objects are supposed to be.\n",
    "* `outline_sigme` allows you to tune how fine the outlines should be.\n",
    "\n",
    "In this code, the python library `napari-segment-blobs-and-things-with-membranes` will be used:\n",
    "```python\n",
    "import napari_segment_blobs_and_things_with_membranes as nsbatwm\n",
    "\n",
    "label_image = nsbatwm.voronoi_otsu_labeling(input_image, spot_sigma=2, outline_sigma=2)\n",
    "```\n",
    "\n",
    "In case you are using the python library `pyclesperanto-prototype`, you can also call the algorithm like this:\n",
    "\n",
    "```python\n",
    "import pyclesperanto_prototype as cle\n",
    "\n",
    "label_image = cle.voronoi_otsu_labeling(input_image, spot_sigma=2, outline_sigma=2)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8adcb927-f3a3-4011-906b-4acb07f25f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I segment small roundish objects, such as nuclei, in an image in case they are very densely packed?\n",
    "\"\"\", output=\"\"\"\n",
    "You can segment densely packed nuclei in an image using the StarDist library.\n",
    "In the following example the nuclei in the `input_image` will be segmented and\n",
    "stored in the `label_image`:\n",
    "\n",
    "```python\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "# creates a pretrained model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
    "\n",
    "# normalize the image\n",
    "axis_norm = (0,1)\n",
    "image = normalize(image, 1,99.8, axis=axis_norm)\n",
    "\n",
    "# segment the image\n",
    "label_image, details = model.predict_instances(input_image)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f6345c-7159-4f83-a816-9989b09ea38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can I segment cells in an image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can use the CellPose library for that.\n",
    "In the following example the cells in the `input_image` will be segmented and\n",
    "stored in the `label_image`:\n",
    "\n",
    "```python\n",
    "from cellpose import models, io\n",
    "\n",
    "model = models.Cellpose(gpu=False, model_type='cyto')\n",
    "\n",
    "channels = [0,0] # This means we are processing single-channel greyscale images.\n",
    "\n",
    "label_image, flows, styles, diams = model.eval(input_image, diameter=None, channels=channels)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df4e4c9a-ba53-435b-abab-293a57c6042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can re-label labels sequentially in a label image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can re-label labels in a label image using scikit-image's `relabel_sequential` function like this:\n",
    "\n",
    "```python\n",
    "from skimage.segmentation import relabel_sequential\n",
    "\n",
    "relabeled_image, _, _ = relabel_sequential(label_image)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40306d47-e439-4875-b550-d92fc0c2ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_example(input=\"\"\"\n",
    "How can expand labels e.g. with a radius of 10 pixels in a label image?\n",
    "\"\"\", output=\"\"\"\n",
    "You can expand labels in a label image using scikit-image's `expand_labels` function like this:\n",
    "\n",
    "```python\n",
    "from skimage.segmentation import expand_labels\n",
    "\n",
    "expanded_labels = expand_labels(filtered_label_image, distance=10)\n",
    "```\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bdf39-3d19-4ceb-8c00-be0cc3f5cc5e",
   "metadata": {},
   "source": [
    "## Preparing training data\n",
    "We need to reformat the data in the [JSON-lines format](https://jsonlines.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c5e0ce7-03ff-43ff-8195-7a4654e85ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dictionary_data, final_file_name):\n",
    "    \n",
    "    with open(final_file_name, 'w') as outfile:\n",
    "        for entry in dictionary_data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "prepare_data(training_data, \"training_data.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc88330-3438-45f4-b573-0899f27313b5",
   "metadata": {},
   "source": [
    "## Uploading training data\n",
    "We can upload the training data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a326d6-e126-40f6-9780-67bfc3ff8247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-xiweY94J061YDcLr7gJZAiWz at 0x1b3f63d2810> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-xiweY94J061YDcLr7gJZAiWz\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 8156,\n",
       "  \"created_at\": 1698937116,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file = openai.File.create(\n",
    "  file=open('training_data.jsonl'),\n",
    "  purpose='fine-tune',\n",
    ")\n",
    "training_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6150a-348e-473c-b444-a108c29bea41",
   "metadata": {},
   "source": [
    "Afterwards, we need to wait until the file is done processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a584547e-3023-4cf9-b40a-102cdde7da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while openai.File.retrieve(training_file.id).status != \"processed\":\n",
    "    print(\"Still processing\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1eb62b-42df-40e1-898a-173e97083e30",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Once the training data is uploaded and processed, we can use it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67d50042-410e-4e2d-8ebb-ec9bbfd8c3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-3ZhPTB0pT3yJENRfutRUQju5 at 0x1b3f4b501d0> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-3ZhPTB0pT3yJENRfutRUQju5\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698937123,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-1cjvymf23JI7jxFOJCdnbsE2\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-xiweY94J061YDcLr7gJZAiWz\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = openai.FineTuningJob.create(training_file=training_file.id, model=\"gpt-3.5-turbo\")\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8f675-ca77-4e7c-935c-f3664e03d83d",
   "metadata": {},
   "source": [
    "Also training will take a while and we need to wait until it succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "230223cc-4af9-474b-a461-d55ec1d16a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n"
     ]
    }
   ],
   "source": [
    "while openai.FineTuningJob.retrieve(job.id).status !=  \"succeeded\":\n",
    "    print(\"Still training\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29663343-a06a-4f59-8126-266891fcdd2b",
   "metadata": {},
   "source": [
    "We can then retrieve the model name and execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1881eab-7deb-48eb-ba83-7f4d805e26c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:personal::8GTbD6B7'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_status = openai.FineTuningJob.retrieve(job.id)\n",
    "\n",
    "model_name = job_status.fine_tuned_model\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd7b98e3-0199-4ab5-9948-3ccdd6ca3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can segment an image showing dense nuclei in Python using the scikit-image library. Here's an example using the Otsu thresholding method:\n",
      "\n",
      "```python\n",
      "from skimage.filters import threshold_otsu\n",
      "from skimage.segmentation import clear_border\n",
      "from skimage.measure import label\n",
      "from skimage.segmentation import watershed\n",
      "\n",
      "# Assume your input image is stored in the `input_image` variable\n",
      "\n",
      "# Apply Otsu thresholding\n",
      "threshold = threshold_otsu(input_image)\n",
      "binary_image = input_image > threshold\n",
      "\n",
      "# Remove border artifacts\n",
      "cleared = clear_border(binary_image)\n",
      "\n",
      "# Label the image\n",
      "label_image = label(cleared)\n",
      "\n",
      "# Apply watershed\n",
      "image_label_overlay = watershed(-input_image, label_image)\n",
      "\n",
      "# The resulting segmented image is stored in the `image_label_overlay` variable\n",
      "```\n",
      "\n",
      "For more advanced segmentation algorithms, you can have a look at the Cellpose or StarDist libraries, which provide more accurate segmentation of cells and nuclei:\n",
      "\n",
      "- Cellpose: https://cellpose.readthedocs.io\n",
      "- StarDist: https://github.com/stardist/stardist\n",
      "\n",
      "Let me know if you need more help!\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=model_name,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot with strong bio-image analysis expertise.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How can I segment an image showing dense nuclei in Python?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec9c4b-8fe0-40ec-81a2-05f4a5d4112a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
